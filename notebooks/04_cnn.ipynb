{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51813e89",
   "metadata": {},
   "source": [
    "rendering placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b89d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# UNet Road Segmentation for Your TIFF Dataset\n",
    "# Structure copied as closely as possible from Massachusetts NB\n",
    "# ============================================================\n",
    "\n",
    "import os, cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as album\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "from pathlib import Path\n",
    "import rasterio\n",
    "\n",
    "# ============================================================\n",
    "# Dataset Paths ðŸ“\n",
    "# ============================================================\n",
    "\n",
    "DATA_DIR = Path(\"data/tiffs\")\n",
    "\n",
    "# We artificially create train/val splits\n",
    "all_tifs = sorted(list(DATA_DIR.glob(\"*.tif\")) + list(DATA_DIR.glob(\"*.tiff\")))\n",
    "random.seed(42)\n",
    "random.shuffle(all_tifs)\n",
    "\n",
    "train_split = int(0.8 * len(all_tifs))\n",
    "val_split   = int(0.9 * len(all_tifs))\n",
    "\n",
    "train_files = all_tifs[:train_split]\n",
    "val_files   = all_tifs[train_split:val_split]\n",
    "test_files  = all_tifs[val_split:]\n",
    "\n",
    "print(\"Train:\", len(train_files))\n",
    "print(\"Val:\", len(val_files))\n",
    "print(\"Test:\", len(test_files))\n",
    "\n",
    "# ============================================================\n",
    "# Class definitions (same style as the Massachusetts NB)\n",
    "# ============================================================\n",
    "\n",
    "class_names = [\"background\", \"road\"]\n",
    "class_rgb_values = [[0,0,0], [255,255,255]]  # for visualization\n",
    "select_class_rgb_values = np.array(class_rgb_values)\n",
    "\n",
    "print(\"All dataset classes:\", class_names)\n",
    "print(\"Class RGB map:\", class_rgb_values)\n",
    "\n",
    "# ============================================================\n",
    "# Helper Functions\n",
    "# ============================================================\n",
    "\n",
    "def visualize(**images):\n",
    "    n = len(images)\n",
    "    plt.figure(figsize=(20,8))\n",
    "    for i, (name, img) in enumerate(images.items()):\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.title(name.replace(\"_\",\" \").title(), fontsize=18)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "def one_hot_encode(mask):\n",
    "    # mask is binary (0/255). convert to 0/1 then stack channels\n",
    "    road = (mask > 0).astype(np.uint8)\n",
    "    background = 1 - road\n",
    "    return np.stack([background, road], axis=-1).astype(\"float32\")\n",
    "\n",
    "def reverse_one_hot(y):\n",
    "    return np.argmax(y, axis=-1)\n",
    "\n",
    "def colour_code_segmentation(mask):\n",
    "    return np.array(class_rgb_values)[mask.astype(int)]\n",
    "\n",
    "# ============================================================\n",
    "# Dataset Class (adapted for TIFF RGB+DEM+MASK)\n",
    "# ============================================================\n",
    "\n",
    "class RoadsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_list, augmentation=None, preprocessing=None):\n",
    "        self.files = file_list\n",
    "        self.augmentation = augmentation\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        tif = self.files[i]\n",
    "        with rasterio.open(tif) as src:\n",
    "            arr = src.read()        # [bands, H, W]\n",
    "        rgb = np.moveaxis(arr[:3], 0, -1).astype(np.uint8)\n",
    "        mask = arr[-1].astype(np.uint8)\n",
    "\n",
    "        # one-hot encode\n",
    "        mask = one_hot_encode(mask)\n",
    "\n",
    "        # Albumentations needs HWC\n",
    "        if self.augmentation:\n",
    "            sample = self.augmentation(image=rgb, mask=mask)\n",
    "            rgb, mask = sample[\"image\"], sample[\"mask\"]\n",
    "\n",
    "        if self.preprocessing:\n",
    "            sample = self.preprocessing(image=rgb, mask=mask)\n",
    "            rgb, mask = sample[\"image\"], sample[\"mask\"]\n",
    "\n",
    "        return rgb, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "# ============================================================\n",
    "# Augmentations\n",
    "# ============================================================\n",
    "\n",
    "def get_training_augmentation():\n",
    "    return album.Compose([\n",
    "        album.RandomCrop(height=256, width=256, always_apply=True),\n",
    "        album.OneOf([\n",
    "            album.HorizontalFlip(p=1),\n",
    "            album.VerticalFlip(p=1),\n",
    "            album.RandomRotate90(p=1),\n",
    "        ], p=0.75),\n",
    "    ])\n",
    "\n",
    "def get_validation_augmentation():\n",
    "    return album.Compose([])\n",
    "\n",
    "def to_tensor(x, **kwargs):\n",
    "    return x.transpose(2,0,1).astype(\"float32\")\n",
    "\n",
    "def get_preprocessing(pre_fn):\n",
    "    return album.Compose([\n",
    "        album.Lambda(image=pre_fn),\n",
    "        album.Lambda(image=to_tensor, mask=to_tensor),\n",
    "    ])\n",
    "\n",
    "# ============================================================\n",
    "# Visualize one example\n",
    "# ============================================================\n",
    "\n",
    "dataset_vis = RoadsDataset(train_files, augmentation=None)\n",
    "rgb, mask = dataset_vis[0]\n",
    "\n",
    "visualize(\n",
    "    original_image = rgb,\n",
    "    ground_truth_mask = colour_code_segmentation(reverse_one_hot(mask)),\n",
    "    one_hot_encoded_mask = reverse_one_hot(mask)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Create Datasets & Loaders\n",
    "# ============================================================\n",
    "\n",
    "ENCODER = \"resnet50\"\n",
    "ENCODER_WEIGHTS = \"imagenet\"\n",
    "CLASSES = [\"background\", \"road\"]\n",
    "ACTIVATION = \"sigmoid\"\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=ENCODER,\n",
    "    encoder_weights=ENCODER_WEIGHTS,\n",
    "    classes=2,\n",
    "    activation=ACTIVATION,\n",
    ")\n",
    "\n",
    "preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)\n",
    "\n",
    "train_dataset = RoadsDataset(\n",
    "    train_files,\n",
    "    augmentation=get_training_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "\n",
    "val_dataset = RoadsDataset(\n",
    "    val_files,\n",
    "    augmentation=get_validation_augmentation(),\n",
    "    preprocessing=get_preprocessing(preprocessing_fn),\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4)\n",
    "\n",
    "# ============================================================\n",
    "# Training Setup\n",
    "# ============================================================\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(DEVICE)\n",
    "\n",
    "loss = smp.utils.losses.DiceLoss()\n",
    "metrics = [smp.utils.metrics.IoU(threshold=0.5)]\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, loss=loss, metrics=metrics,\n",
    "    optimizer=optimizer, device=DEVICE, verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, loss=loss, metrics=metrics,\n",
    "    device=DEVICE, verbose=True\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Train UNet\n",
    "# ============================================================\n",
    "\n",
    "EPOCHS = 5\n",
    "best_iou = 0\n",
    "train_logs_list, val_logs_list = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"\\nEpoch\", epoch)\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    val_logs   = valid_epoch.run(val_loader)\n",
    "\n",
    "    train_logs_list.append(train_logs)\n",
    "    val_logs_list.append(val_logs)\n",
    "\n",
    "    if val_logs[\"iou_score\"] > best_iou:\n",
    "        best_iou = val_logs[\"iou_score\"]\n",
    "        torch.save(model.state_dict(), \"best_unet.pth\")\n",
    "        print(\"Model saved!\")\n",
    "\n",
    "# ============================================================\n",
    "# Prediction on Test Set\n",
    "# ============================================================\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_unet.pth\"))\n",
    "model.eval()\n",
    "\n",
    "test_dataset = RoadsDataset(\n",
    "    test_files,\n",
    "    augmentation=None,\n",
    "    preprocessing=get_preprocessing(preprocessing_fn)\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "test_vis = RoadsDataset(test_files)  # no preprocessing\n",
    "\n",
    "# Show one example\n",
    "idx = 0\n",
    "x, y = test_vis[idx]\n",
    "x_tensor = torch.tensor(x.transpose(2,0,1)).unsqueeze(0).float().to(DEVICE)\n",
    "pred = model(x_tensor).detach().cpu().numpy().squeeze().transpose(1,2,0)\n",
    "pred_mask = reverse_one_hot(pred)\n",
    "gt_mask = reverse_one_hot(y)\n",
    "\n",
    "visualize(\n",
    "    original_image=x,\n",
    "    ground_truth_mask=colour_code_segmentation(gt_mask),\n",
    "    predicted_mask=colour_code_segmentation(pred_mask)\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Evaluate on Test Set\n",
    "# ============================================================\n",
    "\n",
    "test_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, loss=loss, metrics=metrics, device=DEVICE, verbose=True\n",
    ")\n",
    "\n",
    "test_logs = test_epoch.run(test_loader)\n",
    "print(\"Test IoU:\", test_logs[\"iou_score\"])\n",
    "print(\"Test Dice:\", test_logs[\"dice_loss\"])\n",
    "\n",
    "# ============================================================\n",
    "# Plot Loss / IoU Curves\n",
    "# ============================================================\n",
    "\n",
    "df_train = pd.DataFrame(train_logs_list)\n",
    "df_val   = pd.DataFrame(val_logs_list)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(df_train.index, df_train.iou_score, label=\"Train\", lw=3)\n",
    "plt.plot(df_val.index, df_val.iou_score, label=\"Val\", lw=3)\n",
    "plt.title(\"IoU per Epoch\", fontsize=20)\n",
    "plt.grid(); plt.legend(); plt.show()\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(df_train.index, df_train.dice_loss, label=\"Train\", lw=3)\n",
    "plt.plot(df_val.index, df_val.dice_loss, label=\"Val\", lw=3)\n",
    "plt.title(\"Dice Loss per Epoch\", fontsize=20)\n",
    "plt.grid(); plt.legend(); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "road-finding",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
